import sys
import os
import pyaudio
import numpy as np
import sherpa_onnx
import time
import glob
import re
from collections import deque

class Ear:
    def __init__(self):
        print("ğŸ‘‚ è€³æœµæ¨¡å—åˆå§‹åŒ– (V33 è¯­ä¹‰åƒåœ¾è¿‡æ»¤ç‰ˆ)...")
        
        base_dir = "/home/scottwang/lelamp_v2/models/sherpa_paraformer"
        onnx_files = glob.glob(os.path.join(base_dir, "*.onnx"))
        tokens_file = os.path.join(base_dir, "tokens.txt")
        
        if not onnx_files:
            print("âŒ é”™è¯¯: æ¨¡å‹æœªæ‰¾åˆ°")
            sys.exit(1)
            
        try:
            self.recognizer = sherpa_onnx.OfflineRecognizer.from_paraformer(
                paraformer=onnx_files[0],
                tokens=tokens_file,
                num_threads=4,
                sample_rate=16000,
                decoding_method="greedy_search"
            )
        except Exception as e:
            print(f"âŒ å¼•æ“å¯åŠ¨å¤±è´¥: {e}")
            sys.exit(1)

        self.p = pyaudio.PyAudio()
        self.device_index = None
        self.hardware_rate = 16000 
        
        for i in range(self.p.get_device_count()):
            try:
                info = self.p.get_device_info_by_index(i)
                name = info.get('name', '')
                if 'USB' in name and 'Webcam' not in name:
                    self.device_index = i
                    print(f"âœ… é”å®šç‹¬ç«‹éº¦å…‹é£: {name}")
                    break 
            except: pass
            
        for rate in [48000, 44100, 16000]:
            try:
                stream = self.p.open(format=pyaudio.paFloat32, channels=1, rate=rate,
                                   input=True, input_device_index=self.device_index, 
                                   frames_per_buffer=1024)
                stream.close()
                self.hardware_rate = rate
                break
            except: continue
        
        self.calibrate_noise()

    def calibrate_noise(self):
        print("ğŸ¤« æ ¡å‡†åº•å™ª (3.0x)...")
        self.gain = 3.0 
        try:
            stream = self.p.open(format=pyaudio.paFloat32, channels=1, 
                               rate=self.hardware_rate, input=True, 
                               input_device_index=self.device_index, frames_per_buffer=1024)
            noise_levels = []
            for _ in range(30):
                data = stream.read(1024, exception_on_overflow=False)
                samples = np.frombuffer(data, dtype=np.float32) * self.gain
                noise_levels.append(np.sqrt(np.mean(samples**2)))
            stream.close()
            avg = np.mean(noise_levels)
            self.dynamic_threshold = max(avg * 2.5, 0.10) 
            print(f"âœ… é˜ˆå€¼è®¾å®š: {self.dynamic_threshold:.4f}")
        except: self.dynamic_threshold = 0.10

    def _is_gibberish(self, text):
        """
        ğŸ”¥ V33 æ ¸å¿ƒç®—æ³•ï¼šè¯­ä¹‰åƒåœ¾æ£€æµ‹å™¨
        """
        if not text: return True
        if len(text) < 2: return True # è¿‡æ»¤å•å­—
        
        # 1. ç»å¯¹é»‘åå• (å¸¸è§å™ªéŸ³å¹»è§‰)
        blacklist = [
            "the", "The", "å—¯", "å‘ƒ", "åä»¥", "evidence", "Evidence",
            "æ²¡æœ‰æ²¡æœ‰", "è°¢è°¢è§‚çœ‹", "ä¸å®¢æ°”", "å­—å¹•",
            "æˆ‘ä¸ªä¸€ä¸ª", "è¿™çš„ä¸€", "ä¸ªä¸€" # é’ˆå¯¹æ‚¨åé¦ˆçš„ä¹±ç 
        ]
        for b in blacklist:
            if b in text: return True

        # 2. é‡å¤åº¦æ£€æµ‹ (å¦‚: "å¯¹å¯¹å¯¹å¯¹", "å•Šå•Šå•Š")
        # å¦‚æœå»é‡åçš„å­—æ•° < æ€»å­—æ•°çš„ä¸€åŠï¼Œè¯´æ˜å¤§é‡é‡å¤
        if len(set(text)) < len(text) * 0.5:
            return True

        # 3. è™šè¯å¯†åº¦æ£€æµ‹ (æ£€æµ‹ "æˆ‘çš„ä¸€äº†ä¸ªè¿™" è¿™ç§æ— æ„ä¹‰ç»„åˆ)
        # è¿™äº›è¯åœ¨æ­£å¸¸å¥å­ä¸­æ˜¯è¿æ¥è¯ï¼Œä½†å¦‚æœä¸€å¥è¯é‡Œå…¨éƒ½æ˜¯è¿™äº›è¯ï¼Œé‚£å°±æ˜¯ä¹±ç 
        stop_words = set("çš„äº†ç€æ˜¯è¿™ä¸ªæˆ‘ä½ ä»–å®ƒä¸ªä¸€ä¸")
        stop_count = sum(1 for char in text if char in stop_words)
        
        # å¦‚æœä¸€å¥è¯è¶…è¿‡4ä¸ªå­—ï¼Œä¸”80%ä»¥ä¸Šéƒ½æ˜¯è™šè¯ -> åˆ¤å®šä¸ºå™ªéŸ³ç”Ÿæˆçš„ä¹±ç 
        if len(text) > 4 and (stop_count / len(text)) > 0.8:
            return True

        # 4. çº¯éä¸­æ–‡å­—ç¬¦æ£€æµ‹ (è¿‡æ»¤ pure symbols)
        if not re.search(r'[\u4e00-\u9fa5]', text) and not re.search(r'[a-zA-Z]', text):
            return True

        return False

    def listen(self, mouth_ref=None):
        try:
            stream = self.p.open(format=pyaudio.paFloat32, channels=1, 
                               rate=self.hardware_rate, 
                               input=True, input_device_index=self.device_index, 
                               frames_per_buffer=1024)
        except: time.sleep(1); return ""

        print(f"\rğŸ¤ è†å¬ä¸­...", end="", flush=True)
        frames = []
        pre_buffer = deque(maxlen=int(self.hardware_rate/1024*0.5))
        silence_chunks = 0
        is_speaking = False
        
        try:
            while True:
                # ç¡¬ä»¶çº§é™éŸ³
                if mouth_ref and mouth_ref.is_speaking:
                    if is_speaking: return ""
                    time.sleep(0.1); frames.clear(); pre_buffer.clear()
                    continue

                data = stream.read(1024, exception_on_overflow=False)
                samples = np.frombuffer(data, dtype=np.float32) * self.gain
                samples = np.clip(samples, -1.0, 1.0)
                vol = np.sqrt(np.mean(samples**2))
                
                if not is_speaking:
                    pre_buffer.append(samples)
                    if vol > self.dynamic_threshold:
                        is_speaking = True
                        silence_chunks = 0
                        frames.extend(pre_buffer)
                else:
                    frames.append(samples)
                    if vol > (self.dynamic_threshold * 0.7): silence_chunks = 0
                    else: silence_chunks += 1
                
                if is_speaking and silence_chunks > 15: break 
                if len(frames) > int(self.hardware_rate/1024*10): break 

            stream.stop_stream(); stream.close()
            if not is_speaking: return ""
            
            audio_data = np.concatenate(frames)
            if self.hardware_rate != 16000:
                n = int(len(audio_data) * 16000 / self.hardware_rate)
                audio_data = np.interp(np.linspace(0,1,n,endpoint=False), np.linspace(0,1,len(audio_data)), audio_data)
            
            s = self.recognizer.create_stream()
            s.accept_waveform(16000, audio_data)
            self.recognizer.decode_stream(s)
            text = s.result.text.strip()
            
            # ğŸ”¥ åº”ç”¨å¼ºåŠ›è¿‡æ»¤å™¨
            if self._is_gibberish(text): 
                print(f"ğŸ—‘ï¸ è¿‡æ»¤ä¹±ç : {text}")
                return ""
            
            if text:
                print(f"ğŸ‘‚ å¬åˆ°: {text}")
                return text
        except: pass
        return ""
